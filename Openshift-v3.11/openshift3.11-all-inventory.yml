###################################################
### Inventario Ansible para desplegat OpenShift ###
###################################################

## Creamos el grupo que contendra los nodos y maestros
## Que seran habilitados para OpenShift

[OSEv3:children]
masters
nodes
etcd 
lb
nfs
glusters

## Declaramos las variables globales
## Para la configuración
[OSEv3:vars]

#############################################
# Variables Ansible
#############################################

## Establecemos el usuario SSH que realizara la configuración, 
## esta autenticación requiere una contraseña. Si usamos la autentocacion basada en llave, 
## el agente SSH gestionara el acceso
ansible_ssh_user=root

## Si ansible_user no es root, ansible_become debe ser establecido como true, 
#el usuario establecido debe ser configurado para usar sudo sin contraseña
ansible_become=true

##############################################
# OpenShift Variables Basicas
##############################################

## Establecer el tipo de despliegue a realizar. 
## Los valores validos son "origin" y "openshift-enterprise"
openshift_deployment_tipe=openshift-enterprise

## Deshabilitar la revision de requisitos de disco y memoria
openshift_disable_check='disk_availability, memory_availability'

## Establecer la version generica a instalar de OpenShift. 
## Esto es usado principalmente durante la instalación, 
## despues solo confiaremos en la version que se ejecuta en el primer maestro. 
## Esto es muy util para instalaciones basadas en contenedores donde 
## es la estiqueta realmente utilizada para la configuracion del cluster. 
## En instalaciones rpm solo verificamos que la version concida con los los repositorios configurados
openshift_release=v3.11

## Usa esta variable para especificar una etiqueta de imagen de comtenedor para instalar o configurar
openshift_image_tag=v3.11.0

## Usa esta variable para especificar una version RPM para instalar o configurar
openshift_pkg_version = -3.11.0

## Desplegar Operator Lifecycle Manager Tech Preview
## Mas Información en https://coreos.com/blog/introducing-operator-framework
## No recomendado para ambientes de produccion
openshift_enable_olm = true

## Habilita soprte para NFS para los componentes de la infraestructura
openshift_enable_unsupported_configurations=true

#####################################################
## Habilitar CRI-O
#####################################################

openshift_use_crio=True
openshift_use_crio_only=False
openshift_crio_enable_docker_gc=True

###################################################
# OpenShift Locaciones de los Registros
###################################################

# Nota: Se requieren credenciales desde:

## Establece una locacion para imagen alternativa.
## Necesaria si no usas el registro default 'registry.redhat.io'
oreg_url=registry.redhat.io/openshift3/ose-${component}:${version}

## Para el registro de Red Hat, se requiere autentificarse
oreg_auth_user='your_username'
oreg_auth_password='your_password'

## Para las imagenes de Operator Framework
openshift_additional_registry_credentials=[{'host':'registry.connect.redhat.com','user':'<your_username','password':'<your_password','test_image':'mongodb/enterprise-operator:0.3.2'}]

## Establece esta variable como True, si no usas
## el registro predeterminado
openshift_examples_modify_imagestreams=false

## Permite agregar registros inseguros adicionales a los 
## especificados en la configuracion de docker. Para estos registros
## la capa de sockets seguros (SSL), no esta verificada. Se puede
## configurar con el hostname o la ip.
openshift_docker_hosted_registry_insecure=true

##################################################
## OpenShift Variables Master
##################################################

## Establece el puerto para acceder a la 
## API OpenShift Container Platform
openshift_master_api_port=443

## Establece el puerto para acceder a la 
## Web Console. Debe ser el mismo puerto que el del API
openshift_master_console_port=443

## Metodo para definir el HA cuando se despliegan multiples
## masters, por defecto el valor es 'native'
openshift_master_cluster_method=native

## Subdominio predeterminado para usar en rutas expuestas, 
## se debe tener un wildcard dns  para el *.subdominio que apuntara a tu router 
## que se ejecutara en los nods de infraestructura
openshift_master_default_subdomain = subdomain.domain

## Variable que anula el nombre del cluster, 
## que por defecto es el hostname del master 
openshift_master_cluster_hostname = openshift-cluster.domain

## Variable que anula el nombre del cluster que por defecto es el hostname del master, 
## si se esta usando un balanceador de cargas externo, 
## especificar la direccion del balanceador externo 
openshift_master_cluster_public_hostname = openshift-ansible.public.example.com

########################################################
## OpenShift Variables Network
########################################################

## Esta Variable anula el bloque CIDR de la red SDN del cluster. Esta
## esta es la red desde la cual se asignas las IP a los pods. Especifica un
## bloque privado que no tengo conflicto con otros bloques de red
osm_cluster_network_cidr=10.1.0.0/16

## Esta variable configura la subred en donde los servicios seran creados
## en la SDN de OpenShift Container Platform, eespecifique un bloque que
## no entre en conflicto con otros bloques existentes 
openshift_portal_net=172.30.0.0/16

## Esta variable configura el complemento OpenShift SDN que se usara para
## la red de PODs
os_sdn_network_plugin_name='redhat/openshift-ovs-networkpolicy'

##########################################################
### Variables de Autenticacion
##########################################################

## httpasswd auth
openshift_master_identity_providers=[{'name':'httpasswd_auth','login':'true','challenge':'true','kind':'HTPasswordIdentityProvider'}]
## Definiendo usuarios htpasswd 
openshift_master_htpasswd_users={'user1':'<pre-hashsed password>','user2':'<pre-hashsed password>'}
## o apunta al archivo
openshift_master_htpasswd_file=/etc/origin/master/htpasswd

## Permitir todas las autenticaciones
openshift_master_identity_provider=[{'name':'allow_all','login':'true','challenge':'true','kind':'AllowAllPasswordIdentityProvider'}]

## Autenticación LDAP
openshift_master_identity_provider=[{'name':'my_ldap_provider','challenge':'true','login':'true','kind':'LDAPPasswordIdentityProvider','attributes':{'id':['dn'],'email':['mail'],'name':['cn'],'preferredUsername':['uid']},'bindDN':'','bindPassword':'','insecure':'false','url':'ldap://ldap.example.com:389/ou=users,dc=example,dc=com?uid'}]
#Configurando el Certificado ca LDAP
openshift_master_ldap_ca=<ca text>
# o el directorio del Certificado
openshift_master_ldap_ca_file=<ruta para uso del archivo de certificado ca>
## Variables disponibles para configurar certificados 
## De otros proveedores
openshift_master_openid_ca
openshift_master_openind_ca_file
openshift_master_request_header_ca
openshift_master_request_header_ca_file

###############################################
## OpenShift Variables de Loggeo y Metricas
############################################### 

###########################
## Metricas Prometheus 
###########################

## Despliega el Operador del Monitoreo del Cluster si es verdadero
## Esta variable se establece como 'true'
openshift_cluster_monitoring_operator_install=true

## Volumen reclamado del storage persistente para casa estancia
## de Prometheus. Esta variable solo es aplicable si 
## openshift_cluster_monitoring_operator_prometheus_storage_enabled
## esta establecida como verdadera. Por defecto es de 50Gi
openshift_cluster_monitoring_operator_prometheus_storage_capacity="50Gi"

## Volumen Persistente reclamado para cada una de las instancias
## de Alertmanager. Esta variable aplica si
## openshift_cluster_operator_alermanager_storage_enabled esta esta
## Esta establecida como  'true'. Por defecto son 2Gi
openshift_cluster_monitoring_operator_alertmanager_storage_capacity="2Gi"

## Establezca el selector de nodo existente deseado para colocar
## los pods en nodos con etiquetas especificas, el valor por defecto
## es 'node-role.kubernetes.io/infra=true'
openshift_cluster_monitoring_operator_node_selector='node-role.kubernetes.io/infra=true.'


## Habilitar el almacenamiento persistente para los datos de serie temporales
## Se establce en 'false' por default
openshift_cluster_monitoring_operator_prometheus_storage_enabled=false

## Habilita el almacenamiento persistente para las 
## notificaciones y silencios. Esta variable es 'false'
openshift_cluster_monitoring_operator_alertmanager_storage_enabled=false

## Si habilitaste la opcion 
## openshift_cluster_monitoring_operator_prometheus_storage_enabled, establece
## una clase de almacenamiento para asegurar que los pods estan configurados
## Para usar PVC con storageclass. El valor por defecto es ninguno
openshift_cluster_monitoring_operator_prometheus_storage_class_name=""

## Si habilitaste la opcion 
## openshift_cluster_monitoring_operator_prometheus_storage_enabled, establece
## una clase de almacenamiento para asegurar que los pods estan configurados
## Para usar PVC con storageclass. El valor por defecto es ninguno
openshift_cluster_monitoring_operator_alertmanager_storage_class_name=""

###############################
## Metricas
###############################

## Despliega las metricas si es 'true', de lo contrario anula 
## La implementacion
openshift_metrics_install_metrics=true

## El numero de días para almacenar las metricas
## Antes de ser limpiadas
openshift_metrics_duration=1

## Grupo Host NFS
## Al establecer las siguientes variables, se crea un volumen
## NFS durante la instalacion del Clúster con la ruta 
## '<nfs_directory>/<volume_name>' en el host del grupo de 
## hosts [nfs]

openshift_metrics_storage_kind=nfs
openshift_metrics_storage_access_modes=['ReadWriteOnce']
openshift_metrics_storage_nfs_directory=<nfs_directory>
openshift_metrics_storage_nfs_options='*(rw,root_squash)'
openshift_metrics_storage_volume_name=<volume_name>
openshift_metrics_storage_volume_size=10Gi

## Host Externo NFS
## Para usar un volumen NFS externo ya debe existir uno en
## '<nfs_directory>/<volume_name>' en el host de almacenamiento

openshift_metrics_storage_kind=nfs
openshift_metrics_storage_access_modes=['ReadWriteOnce']
openshift_metrics_storage_nfs_directory=<nfs_directory>
openshift_metrics_storage_volume_name=<volume_name>
openshift_metrics_storage_volume_size=10Gi

## Habilita configuraciones no soportadas, que no son 
## compatibles con un entorno productivo 
openshift_enable_unsupported_configurations=True

## Cassandra -- Almacenamiento Efimero(Para pruebas) "emptyDir"
## "pv" para volumenes persistentes, que deben crearse antes de
## la instalación, o "dynamic" para volumenes persistentes dinamicos
openshift_metrics_cassandra_storage_type=pv

## El tamaño reclamado del volumen persistente por cada nodo de 
## Cassandra
openshift_metrics_cassandra_pvc_size=10Gi

## Replicas para el contenedor de Cassandra
openshift_metrics_cassandra_replicas=1

## Limite para la memoria reservada a Cassandra
## Este valor se puede ajustar mediante el script
## De inicio basado en la memoria disponible del
## nodo en el que esta programado
openshift_metrics_cassandra_limits_memory=2Gi

## El limite de CPU para el pod Cassandra "nm"
## donde n es el numeto de milicores
openshift_metrics_cassandra_limits_cpu=1000m

## Establezcas el selector de nodos para asegurar 
## Que los pods se coloquen en nodos con etiquetas 
## Especificas 
openshift_metrics_hakwlar_nodeselector={"node-role.kubernetes.io/ifra":"true"}
openshift_metrics_cassandra_nodeselector={"node-role.kubernetes.io/ifra":"true"}
openshift_metrics_heapster_nodeselector={"node-role.kubernetes.io/ifra":"true"}

## Grafana

## Establezcas el selector de nodos para asegurar 
## Que los pods se coloquen en nodos con etiquetas 
## Especificas 
openshift_metrics_grafana_node_selector={"node-role.kubernetes.io/ifra":"true"}

## Tipo de almacenamiento
openshift_grafana_storage_type=PVC

## Tamaño de almacenamiento Grafana
openshift_grafana_pvc_size=2Gi

openshift_grafana_node_exporter=true

###########################################
## Loggeo de Cluster Usando NFS 
###########################################

## Habilitar el loggeo de cluster, durante la 
## instalacion
openshift_logging_install_logging=true

## Junto con openshift_logging_install_logging
## Ambos se deben establecer en "true" o "false"
openshift_logging_install_eventrouter=true

## Establecer el nodo selector donde se ubicara el Pod 
openshift_logging_es_nodeselector={"node-role.kubernetes.io/infra":"true"}

